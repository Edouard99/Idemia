{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np \n",
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "# from facenet_model import *\n",
    "import torch.optim as optim\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./db_train.raw', 'rb') as f:\n",
    "    data = np.fromfile(f, dtype=np.dtype(np.uint8))\n",
    "    data = data.reshape((111430,56, 56, 3))\n",
    "with open('./label_train.txt', 'rb') as f:\n",
    "    label=f.read().splitlines()\n",
    "    for k,elem in enumerate(label):\n",
    "        label[k]=int(elem)\n",
    "    label=np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, data_0, data_1):\n",
    "        self.samples = []\n",
    "        self.transform=transforms.Compose([  transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                transforms.RandomAffine(20,(0.12,0.12),(0.8,1.2),interpolation=transforms.InterpolationMode.NEAREST,fill=0),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                ])\n",
    "        for img in data_0:\n",
    "            img=transforms.ToTensor()(img)\n",
    "            self.samples.append((img,0))\n",
    "        for img in data_1:\n",
    "            img=transforms.ToTensor()(img)\n",
    "            self.samples.append((img,1))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, id):\n",
    "        (img,label)=self.samples[id]\n",
    "        img=self.transform(img)\n",
    "        return (img,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0=data[np.where(label==0)[0]]\n",
    "data_1=data[np.where(label==1)[0]]\n",
    "data_0_t=data_0[:int(len(data_0)*0.7)]\n",
    "data_1_t=data_1[:int(len(data_1)*0.7)]\n",
    "data_0_v=data_0[int(len(data_0)*0.7):]\n",
    "data_1_v=data_1[int(len(data_1)*0.7):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds=dataset(data_0_t,data_1_t)\n",
    "val_ds=dataset(data_0_v,data_1_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_t = torch.utils.data.DataLoader(train_ds,batch_size=32,shuffle=True,drop_last=True)\n",
    "dataloader_v = torch.utils.data.DataLoader(val_ds,batch_size=32,shuffle=True,drop_last=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, dropout:float, dropout_inter:float,init_weights:bool):\n",
    "        super(FaceNet, self).__init__()\n",
    "        # self.conv1=nn.Conv2d(3,64,kernel_size= 7,stride=2, padding=3)\n",
    "        # self.maxpool1=nn.MaxPool2d(3, stride=2)\n",
    "        self.conv1=ConvModule(3,3,1,1,0)#56\n",
    "        self.conv2=ConvModule(3,64,1,1,0)#56\n",
    "        self.conv3=ConvModule(64,192,3,1,1)\n",
    "        self.maxpool1=nn.MaxPool2d(3,2,1)#28\n",
    "        self.inception1a=InceptionModule(192,64,96,128,16,32,32)#28\n",
    "        self.inception1b=InceptionModule(256,128,128,192,32,96,64)#28\n",
    "        self.maxpool2=nn.MaxPool2d(3,2,1)#14\n",
    "\n",
    "        self.inception2a=InceptionModule(480,192,96,208,16,48,64)#14\n",
    "        self.inception2b=InceptionModule(512,160,112,224,24,64,64)\n",
    "        self.inception2c=InceptionModule(512,128,128,256,24,64,64)\n",
    "        self.inception2d=InceptionModule(512,112,144,288,32,64,64)\n",
    "        self.inception2e=InceptionModule(528,256,160,320,32,128,128)#14\n",
    "        self.maxpool3=nn.MaxPool2d(3,2,1)#7\n",
    "\n",
    "        self.inception3a=InceptionModule(832,256,160,320,32,128,128)\n",
    "        self.inception3b=InceptionModule(832,384,192,384,48,128,128)\n",
    "\n",
    "        self.avgpool= nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.fc = nn.Linear(1024, 1)\n",
    "\n",
    "        self.inter1=InceptionInterModule(512,dropout_inter)\n",
    "        self.inter2=InceptionInterModule(528,dropout_inter)\n",
    "\n",
    "        if init_weights:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                    torch.nn.init.trunc_normal_(m.weight, mean=0.0, std=0.01, a=-2, b=2)\n",
    "                elif isinstance(m, nn.BatchNorm2d):\n",
    "                    nn.init.constant_(m.weight, 1)\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self,x:torch.Tensor,train:bool):\n",
    "        #Nx3x56x56\n",
    "        x=self.conv1(x)\n",
    "        #Nx3x56x56\n",
    "        x=self.conv2(x)\n",
    "        #Nx64x56x56\n",
    "        x=self.conv3(x)\n",
    "        #Nx192x56x56\n",
    "        x=self.maxpool1(x)\n",
    "        #Nx192x28x28\n",
    "        x=self.inception1a(x)\n",
    "        #Nx256x28x28\n",
    "        x=self.inception1b(x)\n",
    "        #Nx480x28x28\n",
    "        x=self.maxpool2(x)\n",
    "        #Nx480x14x14\n",
    "        x=self.inception2a(x)\n",
    "        #Nx512x14x14\n",
    "        if train:\n",
    "            aux1=self.inter1(x)#Nx1\n",
    "        else:\n",
    "            aux1=None\n",
    "        x=self.inception2b(x)\n",
    "        #Nx512x14x14\n",
    "        x=self.inception2c(x)\n",
    "        #Nx512x14x14\n",
    "        x=self.inception2d(x)\n",
    "        #Nx528x14x14\n",
    "        if train:\n",
    "            aux2=self.inter2(x)#Nx1\n",
    "        else:\n",
    "            aux2=None\n",
    "        x=self.inception2e(x)\n",
    "        #Nx832x14x14\n",
    "        x=self.maxpool3(x)\n",
    "        #Nx832x7x7\n",
    "        x=self.inception3a(x)\n",
    "        #Nx832x7x7\n",
    "        x=self.inception3b(x)\n",
    "        #Nx1024x7x7\n",
    "        x=self.avgpool(x)\n",
    "        #Nx1024x1x1\n",
    "        x=nn.Flatten()(x)\n",
    "        #Nx1024\n",
    "        x=self.dropout(x)\n",
    "        #Nx1024\n",
    "        x=self.fc(x)\n",
    "        #Nx1\n",
    "        x=nn.Sigmoid()(x)\n",
    "        #Nx1\n",
    "        return x,aux1,aux2\n",
    "\n",
    "\n",
    "\n",
    "class ConvModule(nn.Module):\n",
    "\n",
    "    def __init__(self, in_c: int, out_c: int, kernel_size: int, stride: int, padding= int):\n",
    "        super(ConvModule, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_c, out_c, kernel_size, stride, padding,  bias=False)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_c, eps=0.001)\n",
    "        self.relu= nn.ReLU()\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.conv(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class L2Pooling(nn.Module):\n",
    "\n",
    "    def __init__(self, kernel_size: int, stride: int, padding= int):\n",
    "        super(L2Pooling, self).__init__()\n",
    "        self.pool = nn.AvgPool2d(kernel_size=kernel_size, stride=stride,padding=padding)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return torch.sqrt(self.pool(x ** 2))\n",
    "\n",
    "\n",
    "\n",
    "class InceptionModule(nn.Module):\n",
    "\n",
    "    def __init__(self, in_c: int, ch1: int, ch3_red: int, ch3: int, ch5_red: int, ch5: int, chpool: int):\n",
    "\n",
    "        super(InceptionModule, self).__init__()\n",
    "        self.branch1=ConvModule(in_c,ch1,kernel_size=1,stride=1,padding=0)\n",
    "        self.branch2=nn.Sequential(\n",
    "            ConvModule(in_c,ch3_red,kernel_size=1,stride=1,padding=0),\n",
    "            ConvModule(ch3_red,ch3,kernel_size=3,stride=1,padding=1)\n",
    "        )\n",
    "        self.branch3=nn.Sequential(\n",
    "            ConvModule(in_c,ch5_red,kernel_size=1,stride=1,padding=0),\n",
    "            ConvModule(ch5_red,ch5,kernel_size=5,stride=1,padding=2)\n",
    "        )\n",
    "        self.branch4=nn.Sequential(\n",
    "            L2Pooling(kernel_size=3,stride=1, padding=1),\n",
    "            ConvModule(in_c,chpool,kernel_size=1,stride=1,padding=0)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x: torch.Tensor):\n",
    "        branch1= self.branch1(x)\n",
    "        branch2= self.branch2(x)\n",
    "        branch3= self.branch3(x)\n",
    "        branch4= self.branch4(x)\n",
    "        return torch.cat([branch1,branch2,branch3,branch4],1)\n",
    "\n",
    "class InceptionInterModule(nn.Module):\n",
    "    def __init__(self, in_c: int, dropout: float):\n",
    "        super(InceptionInterModule, self).__init__()\n",
    "        self.out=nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((4,4)),\n",
    "            ConvModule(in_c,128,kernel_size=1,stride=1,padding=0),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(2048,1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(1024,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self,x: torch.Tensor):\n",
    "        x=self.out(x)\n",
    "        return x\n",
    "        \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device= torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "facenet=FaceNet(0.2,0.7,True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(facenet.parameters(), lr=3e-4, betas=(0.9, 0.999))\n",
    "alpha1=0.2\n",
    "alpha2=0.2\n",
    "num_epochs=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lossfunction(x,y):\n",
    "    num_0=torch.where(y==0)[0].shape[0]\n",
    "    num_1=x.shape[0]-num_0\n",
    "    w0=0.\n",
    "    w1=0.\n",
    "    if num_0!=0:\n",
    "        w0=torch.divide(x.shape[0],(2*num_0),).float()\n",
    "    if num_1!=0:\n",
    "        w1=torch.divide(x.shape[0],(2*num_1),).float()\n",
    "    w=torch.ones_like(x).float()\n",
    "    w[torch.where(y==0)[0]]=w0\n",
    "    w[torch.where(y==1)[0]]=w1\n",
    "    return torch.nn.BCELoss(w)(x.float(),y.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Loss_train=[]\n",
    "Loss_val=[]\n",
    "for epoch in tqdm.tqdm(range(num_epochs)):\n",
    "    L_t=[]\n",
    "    L_v=[]\n",
    "    cpt=0\n",
    "    facenet.train()\n",
    "    for i, dataj in (enumerate(dataloader_t, 0)):\n",
    "        facenet.zero_grad()\n",
    "        x=dataj[0].float().to(device)\n",
    "        yh=dataj[1].float().to(device)\n",
    "        y,aux1,aux2=facenet(x)\n",
    "        loss=lossfunction(y.view(-1),yh)\n",
    "        loss_aux1=lossfunction(aux1.view(-1),yh)\n",
    "        loss_aux2=lossfunction(aux2.view(-1),yh)\n",
    "        total_loss=(loss+alpha1*loss_aux1+alpha2*loss_aux2)/(1+alpha1+alpha2)\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        L_t.append([loss.item(),loss_aux1.item(),loss_aux2.item(),total_loss.item()])\n",
    "    facenet.eval()\n",
    "    for i, dataj in enumerate(dataloader_v, 0):\n",
    "        x=dataj[0].float().to(device)\n",
    "        yh=dataj[1].float().to(device)\n",
    "        y=facenet(x)\n",
    "        loss=lossfunction(y.view(-1),yh)\n",
    "        L_v.append(loss.item())\n",
    "    \n",
    "    err_t=np.mean(L_t,0)\n",
    "    err_v=np.mean(L_v,0)\n",
    "    Loss_train.append(err_t)\n",
    "    Loss_val.append(err_v)\n",
    "    print(\"Erreur Training {} \\t Erreur Val {}\".format(err_t,err_v))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "acb408c112aa627a318ac6bee697c54a21dc0d988d17c05deacc60f98e48531a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
